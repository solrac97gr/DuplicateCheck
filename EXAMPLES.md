# DuplicateCheck Usage Examples

This document provides practical examples of using the DuplicateCheck tool with product descriptions.

## Basic Usage

### 1. Compare Two Product Names

```bash
./duplicatecheck compare "iPhone 14 Pro" "iPhone 13 Pro"
```

**Result:** Shows name similarity only (100% weight on name)

### 2. Compare with Descriptions

```bash
./duplicatecheck compare \
  "Samsung Galaxy S23 Ultra" \
  "Samsung Galaxy S23 Ultra" \
  "512GB Phantom Black with S Pen" \
  "256GB Cloud White with S Pen"
```

**Result:** Shows breakdown of name vs description similarity with 70/30 weighting

## Programmatic Usage

### Example 1: Basic Comparison

```go
package main

import (
    "fmt"
)

func main() {
    engine := NewLevenshteinEngine()
    
    productA := Product{
        ID:          "SKU001",
        Name:        "Apple iPhone 14 Pro Max",
        Description: "Latest flagship iPhone with A16 Bionic chip, ProMotion display, and 48MP camera",
    }
    
    productB := Product{
        ID:          "SKU002",
        Name:        "Apple iPhone 14 Pro Max",
        Description: "Latest flagship iPhone with A16 Bionic chip, ProMotion display, and 48MP camera",
    }
    
    result := engine.Compare(productA, productB)
    
    fmt.Printf("Name Similarity: %.2f%%\n", result.NameSimilarity*100)
    fmt.Printf("Description Similarity: %.2f%%\n", result.DescriptionSimilarity*100)
    fmt.Printf("Combined Similarity: %.2f%%\n", result.CombinedSimilarity*100)
}
```

### Example 2: Custom Weighting for Books

For products like books where the description matters more than the title:

```go
package main

func compareBooksExample() {
    // For books, descriptions (summaries) are very important
    bookWeights := ComparisonWeights{
        NameWeight:        0.3,  // 30% on title
        DescriptionWeight: 0.7,  // 70% on description/summary
    }
    
    engine := NewLevenshteinEngineWithWeights(bookWeights)
    
    book1 := Product{
        ID:   "BOOK001",
        Name: "The Great Gatsby",
        Description: "A novel set in the Jazz Age that tells the story of Jay Gatsby's " +
            "pursuit of the American Dream and his love for Daisy Buchanan. " +
            "A classic American novel exploring themes of wealth, love, and tragedy.",
    }
    
    book2 := Product{
        ID:   "BOOK002", 
        Name: "Great Gatsby",  // Slightly different title
        Description: "A novel set in the Jazz Age that tells the story of Jay Gatsby's " +
            "pursuit of the American Dream and his love for Daisy Buchanan. " +
            "A classic American novel exploring themes of wealth, love, and tragedy.",
    }
    
    result := engine.CompareWithWeights(book1, book2, bookWeights)
    
    // Will show high similarity despite title difference
    // because descriptions are weighted more heavily
    fmt.Printf("Combined Similarity: %.2f%%\n", result.CombinedSimilarity*100)
}
```

### Example 3: Custom Weighting for Fashion

For fashion items where the product name (style, color, size) is critical:

```go
package main

func compareFashionExample() {
    // For fashion, exact name matching is more important
    fashionWeights := ComparisonWeights{
        NameWeight:        0.9,  // 90% on name (style/color/size)
        DescriptionWeight: 0.1,  // 10% on description
    }
    
    engine := NewLevenshteinEngineWithWeights(fashionWeights)
    
    item1 := Product{
        ID:   "SHIRT001",
        Name: "Nike Dri-FIT Training T-Shirt Blue Size L",
        Description: "Comfortable athletic wear perfect for workouts",
    }
    
    item2 := Product{
        ID:   "SHIRT002",
        Name: "Nike Dri-FIT Training T-Shirt Blue Size M",  // Different size!
        Description: "Comfortable athletic wear ideal for gym sessions",
    }
    
    result := engine.CompareWithWeights(item1, item2, fashionWeights)
    
    // Will show lower similarity because name is weighted heavily
    // and the size difference matters
    fmt.Printf("Combined Similarity: %.2f%%\n", result.CombinedSimilarity*100)
}
```

### Example 4: Batch Processing with Descriptions

```go
package main

func batchProcessingExample() {
    engine := NewLevenshteinEngine()
    
    products := []Product{
        {
            ID:   "P001",
            Name: "Sony WH-1000XM5",
            Description: "Premium noise-cancelling headphones with 30-hour battery, " +
                "LDAC audio, and exceptional sound quality. Latest model from Sony.",
        },
        {
            ID:   "P002",
            Name: "Sony WH-1000XM4",
            Description: "Premium noise-cancelling headphones with 30-hour battery, " +
                "LDAC audio, and exceptional sound quality. Previous generation model.",
        },
        {
            ID:   "P003",
            Name: "Bose QuietComfort 45",
            Description: "Wireless noise-cancelling headphones with comfortable design " +
                "and 24-hour battery life. Premium audio experience.",
        },
    }
    
    threshold := 0.85
    duplicates := engine.FindDuplicates(products, threshold)
    
    fmt.Printf("Found %d potential duplicates:\n", len(duplicates))
    for _, dup := range duplicates {
        fmt.Printf("  %s <-> %s: %.2f%% similar\n", 
            dup.ProductA.ID, dup.ProductB.ID, dup.CombinedSimilarity*100)
        fmt.Printf("    (Name: %.2f%%, Desc: %.2f%%)\n",
            dup.NameSimilarity*100, dup.DescriptionSimilarity*100)
    }
}
```

## Performance Considerations

### Long Descriptions (500-3000 characters)

The Levenshtein algorithm handles long descriptions efficiently:

```go
// Example with realistic long ecommerce descriptions
product1 := Product{
    ID:   "LAPTOP001",
    Name: "MacBook Pro 16-inch M2 Max",
    Description: strings.Repeat("Very detailed product description. ", 80), // ~2400 chars
}

product2 := Product{
    ID:   "LAPTOP002", 
    Name: "MacBook Pro 16-inch M2 Pro",
    Description: strings.Repeat("Very detailed product description. ", 80), // ~2400 chars
}

// This comparison takes ~15-20ms with current implementation
result := engine.Compare(product1, product2)
```

**Performance Tips:**
- ‚úÖ Descriptions up to 1000 chars: < 5ms per comparison
- ‚úÖ Descriptions 1000-2000 chars: ~10-15ms per comparison
- ‚úÖ Descriptions 2000-3000 chars: ~15-25ms per comparison
- üí° For catalogs with >10,000 products, consider parallel processing or indexing strategies

### Optimizing for Large Catalogs

```go
package main

import (
    "sync"
)

func parallelDuplicateDetection(products []Product, threshold float64) []ComparisonResult {
    engine := NewLevenshteinEngine()
    
    var duplicates []ComparisonResult
    var mu sync.Mutex
    var wg sync.WaitGroup
    
    // Process in chunks
    chunkSize := 100
    for i := 0; i < len(products); i += chunkSize {
        end := i + chunkSize
        if end > len(products) {
            end = len(products)
        }
        
        wg.Add(1)
        go func(chunk []Product) {
            defer wg.Done()
            
            results := engine.FindDuplicates(chunk, threshold)
            
            mu.Lock()
            duplicates = append(duplicates, results...)
            mu.Unlock()
        }(products[i:end])
    }
    
    wg.Wait()
    return duplicates
}
```

## Real-World Scenarios

### Scenario 1: User Article Duplicate Detection (500 Articles)

**Use Case:** Check if a user's new article is a duplicate of any of their 500 existing articles.

```go
func checkUserArticleForDuplicates(newArticle Product, userArticles []Product) {
    engine := NewLevenshteinEngine()
    threshold := 0.85 // 85% similarity threshold
    
    fmt.Printf("Checking article '%s' against %d existing articles...\n", 
        newArticle.Name, len(userArticles))
    
    duplicatesFound := []ComparisonResult{}
    
    for _, existing := range userArticles {
        result := engine.Compare(newArticle, existing)
        
        if result.CombinedSimilarity >= threshold {
            duplicatesFound = append(duplicatesFound, result)
        }
    }
    
    if len(duplicatesFound) > 0 {
        fmt.Printf("‚ö†Ô∏è  Found %d potential duplicates:\n", len(duplicatesFound))
        for _, dup := range duplicatesFound {
            fmt.Printf("  - %s: %.2f%% similar (Name: %.2f%%, Content: %.2f%%)\n",
                dup.ProductB.ID,
                dup.CombinedSimilarity*100,
                dup.NameSimilarity*100,
                dup.DescriptionSimilarity*100)
        }
        fmt.Println("‚õî Article rejected: Too similar to existing content")
    } else {
        fmt.Println("‚úÖ Article is unique - approved for publication")
    }
}

// Example usage
newArticle := Product{
    ID:   "NEW_001",
    Name: "Understanding Machine Learning Algorithms in 2025",
    Description: "Machine learning has revolutionized how we approach data analysis...",
}

userArticles := loadUserArticles(userID) // Load user's 500 articles
checkUserArticleForDuplicates(newArticle, userArticles)

// Performance: ~500-600ms to scan 500 articles with descriptions
```

### Scenario 2: Batch Article Submission

**Use Case:** A user submits 10 new articles - check all of them against their 500 existing articles.

```go
func batchCheckArticles(newArticles, existingArticles []Product) {
    engine := NewLevenshteinEngine()
    threshold := 0.85
    
    approved := []Product{}
    rejected := []Product{}
    
    for _, newArticle := range newArticles {
        hasDuplicate := false
        
        for _, existing := range existingArticles {
            result := engine.Compare(newArticle, existing)
            
            if result.CombinedSimilarity >= threshold {
                rejected = append(rejected, newArticle)
                hasDuplicate = true
                fmt.Printf("‚ùå %s: Duplicate of %s (%.2f%% similar)\n",
                    newArticle.ID, existing.ID, result.CombinedSimilarity*100)
                break // Found duplicate, move to next article
            }
        }
        
        if !hasDuplicate {
            approved = append(approved, newArticle)
            fmt.Printf("‚úÖ %s: Approved\n", newArticle.ID)
        }
    }
    
    fmt.Printf("\nResults: %d approved, %d rejected\n", 
        len(approved), len(rejected))
}

// Performance for 10 articles vs 500 existing:
// - Average: ~5 seconds total
// - Early exit optimization reduces comparisons significantly
```

### Scenario 3: Custom Weighting for Different Content Types

**Use Case:** Blog posts where titles are critical vs. academic papers where content matters more.

```go
// For blog posts - title is very important
func checkBlogPost(newPost, existingPost Product) float64 {
    weights := ComparisonWeights{
        NameWeight:        0.8,  // 80% on title
        DescriptionWeight: 0.2,  // 20% on content
    }
    engine := NewLevenshteinEngineWithWeights(weights)
    result := engine.CompareWithWeights(newPost, existingPost, weights)
    return result.CombinedSimilarity
}

// For academic papers - content is more important
func checkAcademicPaper(newPaper, existingPaper Product) float64 {
    weights := ComparisonWeights{
        NameWeight:        0.3,  // 30% on title
        DescriptionWeight: 0.7,  // 70% on abstract/content
    }
    engine := NewLevenshteinEngineWithWeights(weights)
    result := engine.CompareWithWeights(newPaper, existingPaper, weights)
    return result.CombinedSimilarity
}
```

### Scenario 1: Detecting Near-Duplicates in Import

```go
// When importing new products, check against existing catalog
func checkImportForDuplicates(newProducts, existingCatalog []Product) {
    engine := NewLevenshteinEngine()
    threshold := 0.90  // 90% similarity = very likely duplicate
    
    for _, newProd := range newProducts {
        for _, existing := range existingCatalog {
            result := engine.Compare(newProd, existing)
            
            if result.CombinedSimilarity >= threshold {
                fmt.Printf("‚ö†Ô∏è  Potential duplicate detected!\n")
                fmt.Printf("   New: %s - %s\n", newProd.Name, newProd.ID)
                fmt.Printf("   Existing: %s - %s\n", existing.Name, existing.ID)
                fmt.Printf("   Similarity: %.2f%%\n", result.CombinedSimilarity*100)
                
                // Flag for manual review or auto-reject
            }
        }
    }
}
```

### Scenario 2: Merge Suggestions

```go
// Suggest which products should be merged
func suggestMerges(products []Product) {
    engine := NewLevenshteinEngine()
    
    // Very high threshold = confident merge suggestions
    highConfidence := engine.FindDuplicates(products, 0.95)
    
    // Medium threshold = manual review needed
    mediumConfidence := engine.FindDuplicates(products, 0.85)
    
    fmt.Println("Auto-merge candidates (95%+ similar):")
    for _, dup := range highConfidence {
        fmt.Printf("  ‚úÖ Merge %s into %s\n", dup.ProductA.ID, dup.ProductB.ID)
    }
    
    fmt.Println("\nManual review needed (85-95% similar):")
    for _, dup := range mediumConfidence {
        if dup.CombinedSimilarity < 0.95 {
            fmt.Printf("  üîç Review: %s vs %s (%.2f%% similar)\n", 
                dup.ProductA.ID, dup.ProductB.ID, dup.CombinedSimilarity*100)
        }
    }
}
```

## Testing Your Algorithm Configuration

```go
package main

import "testing"

func TestCustomWeightsForYourDomain(t *testing.T) {
    // Define weights for your specific product type
    weights := ComparisonWeights{
        NameWeight:        0.6,
        DescriptionWeight: 0.4,
    }
    
    engine := NewLevenshteinEngineWithWeights(weights)
    
    // Test with your real product data
    testCases := []struct {
        name           string
        productA       Product
        productB       Product
        expectedMinSim float64
        shouldBeDupe   bool
    }{
        {
            name: "Known duplicate from your catalog",
            productA: Product{
                ID:          "YOUR_PROD_1",
                Name:        "...",
                Description: "...",
            },
            productB: Product{
                ID:          "YOUR_PROD_2", 
                Name:        "...",
                Description: "...",
            },
            expectedMinSim: 0.90,
            shouldBeDupe:   true,
        },
        // Add more test cases from your real data
    }
    
    for _, tc := range testCases {
        t.Run(tc.name, func(t *testing.T) {
            result := engine.CompareWithWeights(tc.productA, tc.productB, weights)
            
            if tc.shouldBeDupe && result.CombinedSimilarity < tc.expectedMinSim {
                t.Errorf("Expected duplicate but similarity too low: %.2f%%", 
                    result.CombinedSimilarity*100)
            }
        })
    }
}
```

## Next Steps

1. **Experiment with weights** - Try different NameWeight/DescriptionWeight ratios for your product type
2. **Benchmark with your data** - Test with real products from your catalog
3. **Tune thresholds** - Adjust the similarity threshold based on false positive/negative rates
4. **Scale up with Hybrid** - Use the hybrid engine for catalogs with 500+ products

## Large Catalog Examples (500+ Products)

### Example: Using Hybrid Engine for Performance

When you have a large catalog and need to check many products, use the Hybrid engine:

```go
package main

import (
    "fmt"
    "time"
)

func main() {
    // Load your entire product catalog
    allProducts := loadProductsFromDatabase() // 10,000 products
    
    // Create hybrid engine for massive speedup
    engine := NewHybridEngine()
    
    // Build index once (one-time cost: ~145ms for 1000 products)
    start := time.Now()
    engine.BuildIndex(allProducts)
    fmt.Printf("Indexed %d products in %v\n", len(allProducts), time.Since(start))
    
    // Now check a new product (ultra-fast: ~15¬µs per query)
    newProduct := Product{
        ID:          "NEW_SKU",
        Name:        "Apple AirPods Pro 2nd Gen",
        Description: "Active Noise Cancellation with Adaptive Transparency, up to 6 hours listening time",
    }
    
    // Find duplicates in microseconds instead of seconds!
    duplicates := engine.FindDuplicatesForOne(newProduct, 0.85)
    
    fmt.Printf("Found %d potential duplicates:\n", len(duplicates))
    for _, dup := range duplicates {
        fmt.Printf("  - %s: %.2f%% similar\n", 
            dup.ProductB.Name, 
            dup.CombinedSimilarity*100)
    }
}
```

### Example: Real-time API with Pre-indexed Catalog

```go
package main

import (
    "encoding/json"
    "net/http"
    "sync"
)

var (
    catalogEngine *HybridEngine
    engineMutex   sync.RWMutex
)

func init() {
    // Initialize and index catalog at startup
    catalogEngine = NewHybridEngine()
    products := loadAllProducts()
    catalogEngine.BuildIndex(products)
}

func checkDuplicateHandler(w http.ResponseWriter, r *http.Request) {
    var newProduct Product
    if err := json.NewDecoder(r.Body).Decode(&newProduct); err != nil {
        http.Error(w, err.Error(), http.StatusBadRequest)
        return
    }
    
    // Ultra-fast duplicate check (~15¬µs)
    engineMutex.RLock()
    duplicates := catalogEngine.FindDuplicatesForOne(newProduct, 0.85)
    engineMutex.RUnlock()
    
    json.NewEncoder(w).Encode(map[string]interface{}{
        "found_duplicates": len(duplicates) > 0,
        "matches":          duplicates,
        "query_time_us":    "~15",
    })
}

func reindexHandler(w http.ResponseWriter, r *http.Request) {
    // Rebuild index when catalog changes
    products := loadAllProducts()
    
    newEngine := NewHybridEngine()
    newEngine.BuildIndex(products)
    
    // Atomic swap
    engineMutex.Lock()
    catalogEngine = newEngine
    engineMutex.Unlock()
    
    json.NewEncoder(w).Encode(map[string]string{
        "status": "reindexed",
        "products": fmt.Sprintf("%d", len(products)),
    })
}

func main() {
    http.HandleFunc("/check-duplicate", checkDuplicateHandler)
    http.HandleFunc("/reindex", reindexHandler)
    
    fmt.Println("Duplicate detection API listening on :8080")
    fmt.Println("  POST /check-duplicate - Check if product is duplicate")
    fmt.Println("  POST /reindex - Rebuild catalog index")
    http.ListenAndServe(":8080", nil)
}
```

### Example: Performance Comparison

```go
package main

import (
    "fmt"
    "time"
)

func comparePerformance() {
    articles := generateUserArticles(500)
    newArticle := Product{
        ID:   "NEW",
        Name: "Understanding Machine Learning",
        Description: "A comprehensive guide to ML algorithms...",
    }
    
    // Naive approach
    naiveEngine := NewLevenshteinEngine()
    start := time.Now()
    naiveResults := naiveEngine.FindDuplicates(
        append([]Product{newArticle}, articles...), 
        0.85,
    )
    naiveTime := time.Since(start)
    
    // Hybrid approach
    hybridEngine := NewHybridEngine()
    hybridEngine.BuildIndex(articles)
    
    start = time.Now()
    hybridResults := hybridEngine.FindDuplicatesForOne(newArticle, 0.85)
    hybridTime := time.Since(start)
    
    fmt.Printf("Naive approach:  %v (%d results)\n", naiveTime, len(naiveResults))
    fmt.Printf("Hybrid approach: %v (%d results)\n", hybridTime, len(hybridResults))
    fmt.Printf("Speedup: %.0fx faster\n", float64(naiveTime)/float64(hybridTime))
}
```

**Expected Output:**
```
Naive approach:  137ms (1 results)
Hybrid approach: 308¬µs (1 results)
Speedup: 444x faster
```

### Example: Batch Processing with Progress

```go
package main

import (
    "fmt"
    "time"
)

func batchCheckDuplicates(newProducts []Product, catalog []Product) {
    engine := NewHybridEngine()
    
    // Index once
    fmt.Printf("Indexing %d catalog products...\n", len(catalog))
    start := time.Now()
    engine.BuildIndex(catalog)
    fmt.Printf("Indexed in %v\n\n", time.Since(start))
    
    // Check each new product
    totalDuplicates := 0
    start = time.Now()
    
    for i, product := range newProducts {
        duplicates := engine.FindDuplicatesForOne(product, 0.85)
        totalDuplicates += len(duplicates)
        
        if len(duplicates) > 0 {
            fmt.Printf("[%d/%d] %s - Found %d duplicates\n", 
                i+1, len(newProducts), product.Name, len(duplicates))
        }
        
        // Progress every 10 products
        if (i+1)%10 == 0 {
            elapsed := time.Since(start)
            avgTime := elapsed / time.Duration(i+1)
            fmt.Printf("  Progress: %d/%d (avg %v per product)\n", 
                i+1, len(newProducts), avgTime)
        }
    }
    
    totalTime := time.Since(start)
    fmt.Printf("\nProcessed %d products in %v\n", len(newProducts), totalTime)
    fmt.Printf("Found %d total duplicates\n", totalDuplicates)
    fmt.Printf("Average: %v per product\n", totalTime/time.Duration(len(newProducts)))
}
```

## Performance Guidelines

| Scenario | Recommended Engine | Expected Performance |
|----------|-------------------|---------------------|
| <100 products | Levenshtein | ~25-50ms per batch |
| 100-500 products | Either (test both) | Levenshtein: ~125ms<br>Hybrid: ~15¬µs |
| 500-1000 products | **Hybrid** | ~25¬µs per query |
| 1000-10,000 products | **Hybrid** | ~25-35¬µs per query |
| 10,000+ products | **Hybrid** | ~35-50¬µs per query |

See `PERFORMANCE.md` for detailed benchmark results and tuning tips.

See the main README for information about adding new algorithms to the system.
